hi everyone so recently I gave a 30-minute talk on large language models just kind of like an intro talk um
unfortunately that talk was not recorded but a lot of people came to me after the talk and they told me that uh they
really liked the talk so I would just I thought I would just re-record it and basically put it up on YouTube so here
we go the busy person's intro to large language models director Scott okay so let's begin first of all what is a large
language model really well a large language model is just two files right um there will be two files in this
hypothetical directory so for example working with a specific example of the Llama 270b model this is a large
language model released by meta Ai and this is basically the Llama series of language models the second iteration of
it and this is the 70 billion parameter model of uh of this series so there's
multiple models uh belonging to the Llama 2 Series uh 7 billion um 13
billion 34 billion and 70 billion is the biggest one now many people like this model specifically because it is
probably today the most powerful open weights model so basically the weights and the architecture and a paper was all
released by meta so anyone can work with this model very easily uh by themselves
uh this is unlike many other language models that you might be familiar with for example if you're using chat GPT or something like that uh the model
architecture was never released it is owned by open aai and you're allowed to use the language model through a web
interface but you don't have actually access to that model so in this case the Llama 270b model is really just two
files on your file system the parameters file and the Run uh some kind of a code that runs those
parameters so the parameters are basically the weights or the parameters of this neural network that is the
language model we'll go into that in a bit because this is a 70 billion parameter model uh every one of those
parameters is stored as 2 bytes and so therefore the parameters file here is
140 gigabytes and it's two bytes because this is a float 16 uh number as the data
type now in addition to these parameters that's just like a large list of parameters uh for that neural network
you also need something that runs that neural network and this piece of code is implemented in our run file now this
could be a C file or a python file or any other programming language really uh it can be written any arbitrary language
but C is sort of like a very simple language just to give you a sense and uh it would only require about 500 lines of
C with no other dependencies to implement the the uh neural network architecture uh and that uses basically
the parameters to run the model so it's only these two files you can take these two files and you can take your MacBook
